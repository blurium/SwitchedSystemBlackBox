 % !TEX root = main.tex
We now formally present the problem we will be considering from now. We recall that our observations are traces of the form $(x_k,x_{k+1},\dots,x_{k+l})$ for some arbitrary $l \in \N_{>0}$, and that we do not have access to the mode applied to the system at each time step. 

To generate these traces, we assume that we can randomly pick a finite number of initial conditions $x_0^i \in \R^n$, and that we can randomly generate a sequence of $l$ modes applied to each of these points. Hence, the probability event corresponding to a given observed trace $(x_k,x_{k+1},\dots,x_{k+l})$ is another $(l+1)$-tuple $(x_k,j_1,\dots,j_l)$. More precisely, we assume that we can uniformly sample such $(l+1)$-tuples in $Z_l = \sphere \times M^l$, giving us a sample denoted by 
$$\omega_N := \{(x_0^1, j_{1,1}, \dots, j_{1,l}), (x_0^2, j_{2,1}, \dots, j_{2,l}), \ldots, (x_0^N, j_{N,1},\dots, j_{N,l})\} \subset Z_l.$$

By uniformly sampling, we mean that the points in $\omega_N$ are drawn according to the measure $\mu_l$, i.e., the points $x_0^i$ are drawn from $\sphere$ according to the classical spherical measure $\sigma^{n-1}$, and the modes are drawn from $M$ according to the classical uniform measure $\mu_M$ at each time step. The space of sampling for the initial conditions is restricted to $\sphere$ since, as we recall, by Property \ref{property:homogeneity}, the system is homogeneous. \textcolor{red}{Motivate why uniform sampling for modes: We have random observations of the state, we do not know the process that picks the modes, and we model this process with a random distribution. By default we take this distribution uniform since we cannot say some states are privileged a priori. But a future step would be to consider different distributions and extend our guarantees to them.}

From a sample $\omega_N$, we obtain the set of corresponding available observations $W_{\omega_N} := \{(x_0^1,x_1^1, \dots, x_l^1), (x_0^2,x_1^2, \dots, x_l^2), \ldots, (x_0^N,x_1^N, \dots, x_l^N)\}$, which satisfy $$x_l^i= A_{j_{i,1}} \dots A_{j_{i,l}} x_0^i, \ \forall\ (x_0^i,x_1^i,\dots, x_l^i) \in W_{\omega_N}.$$

In this work, we aim at understanding what type of guarantees one can obtain on the stability of System \eqref{eq:switchedSystem} (that is, on the JSR of $\cM$) from a finite, uniformly sampled, set of data. More precisely, we answer the following problem:

\begin{problem} 
Consider a finite set of matrices $\cM,$ describing a switched system \eqref{eq:switchedSystem}, and suppose that one has a set of $N$ observations $$\omega_N=\{(x_0^1, j_{1,1}, \dots, j_{1,l}), (x_0^2, j_{2,1}, \dots, j_{2,l}), \ldots, (x_0^N, j_{N,1},\dots, j_{N,l})\},$$ sampled according to the uniform measure $\mu_l$ on $Z_l$.

\begin{itemize}
\item For a given number $\beta \in (0,1)$, provide an upper bound $\overline{\rho(\omega_N)}$ on $\rho(\cM)$, together with a level of confidence $\beta$, that is, a number $\overline{\rho(\omega_N)}$ such that $$\mu_l \left( \{\omega_N: \ \rho(\cM) \leq \overline{\rho(\omega_N)} \} \right) \geq \beta. $$
 
\item For the same given level of confidence $\beta$, provide a lower bound $\underline{\rho(\cM)}$ on $\rho(\cM)$.
\end{itemize}
\end{problem}

In fact, we will see in Section 4 that there is no need for a such level of confidence $\beta$ in the case of the lower bound; indeed, in Theorem  \ref{thm:lowerbound}, we derive a deterministic lower bound for a given (sufficiently high) number of observations. 

The idea from now will be to leverage the fact that conditions for the existence of a CQLF for \eqref{eq:switchedSystem} can be obtained by considering a finite number of traces of the form $(x_k,x_{k+1}, \dots, x_{l}) \in \R^n$.